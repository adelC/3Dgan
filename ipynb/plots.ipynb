{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "plots.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adelC/3Dgan/blob/adel%2Fpgan/ipynb/plots.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFmpU3sbdr2Z"
      },
      "source": [
        "# Loading Google Drive and mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVsG4Ox9Zc_0",
        "outputId": "36c3152b-60bb-4c42-cbad-29d27f0a419c"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEKLIUMZTS1z",
        "outputId": "40ac2cd8-9ae3-4c6a-feb2-bf9fe84ccdf7"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLDHHVzLTaMl",
        "outputId": "167f1f0e-9ae8-4727-b125-aee356ef83d7"
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xESYzMEshWlQ",
        "outputId": "845f2116-7123-4b4a-c780-e9b86a410b9d"
      },
      "source": [
        "!pip install horovod"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting horovod\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/93/503830d0de5c7390d65c94ffa60db3719826f3deeb0d055fcfa35b4d7927/horovod-0.21.1.tar.gz (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from horovod) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from horovod) (5.4.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from horovod) (3.13)\n",
            "Requirement already satisfied: cffi>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from horovod) (1.14.4)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from horovod) (0.8)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.4.0->horovod) (2.20)\n",
            "Building wheels for collected packages: horovod\n",
            "  Building wheel for horovod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for horovod: filename=horovod-0.21.1-cp36-cp36m-linux_x86_64.whl size=20544593 sha256=e5d34c1796fd37126d791cb24fb04c7936ee013f0360f5da064d6137324763c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/91/85/8e868c735394d482d578639f2dc392ae7f69e11a58a95d6108\n",
            "Successfully built horovod\n",
            "Installing collected packages: horovod\n",
            "Successfully installed horovod-0.21.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7VCQigqdoOA"
      },
      "source": [
        "## Setting ROOT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0MDcSPdbjbj"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/tools/root/\")\n",
        "sys.path.append(\"/content/drive/MyDrive/tools/root/bin/\")\n",
        "sys.path.append(\"/content/drive/MyDrive/tools/root/include/\")\n",
        "sys.path.append(\"/content/drive/MyDrive/tools/root/lib/\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxxTcYDGdd5y"
      },
      "source": [
        "import ROOT"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5BkRdnYT20b",
        "outputId": "b1cfe6e4-ed80-473f-8ffc-868aaca270f3"
      },
      "source": [
        "%cd /content/drive/MyDrive/code/cern/3Dgan/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/code/cern/3Dgan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "F5LfG3A4U1gs",
        "outputId": "1cb4f697-9249-4328-bf6a-d1df58306074"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "from os import path\n",
        "import argparse\n",
        "import h5py\n",
        "import ROOT\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import keras.backend as K\n",
        "import horovod.tensorflow as hvd\n",
        "from scripts.GANutils import GetData, GetAngleData, GetDataFiles, generate, generate2,  safe_mkdir\n",
        "from scripts.hdf_to_numpy import resize, restore_pic\n",
        "import scripts.ROOTutils as my\n",
        "from tensorflow.core.protobuf import rewriter_config_pb2\n",
        "import time\n",
        "import importlib\n",
        "sys.path.insert(0,'../')\n",
        "try:\n",
        "    import setGPU #if Caltech\n",
        "except:\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_parser():\n",
        "   # To parse the input parameters to the script\n",
        "   parser = argparse.ArgumentParser()\n",
        "   parser.add_argument('--gweights', type=str, nargs='+', default=['../weights/3dgan_weights_gan_training_epsilon_2_500GeV/params_generator_epoch_021.hdf5'], help=\"Complete PATH to the trained weights to test with hdf5 extension\")\n",
        "   parser.add_argument('--ang', default=1, type=int, help=\"If using angle vefsion\")\n",
        "   parser.add_argument('--pgan', type=int, default=1, help='If using PGAN')\n",
        "   parser.add_argument('--particle', default='Ele', type=str, help=\"particle type\")\n",
        "   parser.add_argument('--labels', type=str, nargs='+', default=[''], help=\"labels for different weights\")\n",
        "   parser.add_argument('--xscales',  type=float, nargs='+', help=\"scaling factor for cell energies\")\n",
        "   parser.add_argument('--datapath', default='full2', help='Data to check the output obtained')\n",
        "   parser.add_argument('--outdir', default= 'results/short_analysis', help='Complete PATH to save the output plot')\n",
        "   parser.add_argument('--numevents', action='store', type=int, default=10000, help='Max limit for events used for validation')\n",
        "   parser.add_argument('--latent', action='store', type=int, help='size of latent space to sample')\n",
        "   parser.add_argument('--dformat', action='store', type=str, default='channels_last', help='keras image format')\n",
        "   parser.add_argument('--error', type=int, default=0, help='add relative errors to plots')\n",
        "   parser.add_argument('--stest', type=int, default=0, help='add ktest to plots')\n",
        "   parser.add_argument('--norm', type=int, default=1, help='normalize shower shapes')\n",
        "   parser.add_argument('--ifC', type=int, default=0, help='generate .C files')\n",
        "   parser.add_argument('--leg', type=int, default=1, help='draw legend')\n",
        "   parser.add_argument('--grid', type=int, default=0, help='draw grid')\n",
        "   return parser\n",
        "\n",
        "\n",
        "def get_session():\n",
        "    gopts = tf.GraphOptions(place_pruned_graph=True)\n",
        "    config = tf.ConfigProto(graph_options=gopts, allow_soft_placement=True)\n",
        "    config.graph_options.rewrite_options.layout_optimizer = rewriter_config_pb2.RewriterConfig.OFF\n",
        "    sess = tf.Session(config=config)\n",
        "    return sess\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "   #parser = get_parser()\n",
        "   #args = parser.parse_args()\n",
        "   #gweights = args.gweights if isinstance(args.gweights, list) else [args.gweights]\",\n",
        "   #labels = args.labels if isinstance(args.labels, list) else [args.labels]\",\n",
        "   ang = 1 #args.ang\",\n",
        "   pgan = 1 #args.pgan\",\n",
        "   particle = \"Ele\" #args.particle\",\n",
        "   latent = 256 # args.latent\\n\",\n",
        "   datapath = \"/content/drive/MyDrive/dataset/cern/Ele_VarAngleMeas_100_200_000.h5\" #args.datapath\\n\",\n",
        "   outdir = \"output\" #args.outdir\",\n",
        "   numevents= 10000 #args.numevents\\n\",\n",
        "   dformat= \"channels_last\" #args.dformat\",\n",
        "   error = 0 #args.error\",\n",
        "   stest = 0 #args.stest\",\n",
        "   norm = 1 #args.norm\",\n",
        "   C = 0 #args.ifC\",\n",
        "   leg = 1 #args.leg\",\n",
        "   grid = 0 #args.grid\",\n",
        "   xscales = 1.\n",
        "\n",
        "   dscale = 50.\n",
        "   if not latent:\n",
        "       latent = 256\n",
        "   if not xscales:\n",
        "       xscales = [1] * len(gweights)\n",
        "   xpower = 0.85\n",
        "   #if datapath=='reduced':\n",
        "   #    datapath = \"/storage/group/gpu/bigdata/gkhattak/*Measured3ThetaEscan/*.h5\"  # Data path 100-200 GeV\n",
        "   #elif datapath=='full':\n",
        "   #    datapath = \"/storage/group/gpu/bigdata/LCDLargeWindow/LCDLargeWindow/varangle/*scan/*scan_RandomAngle_*.h5\" # culture plate\n",
        "   #else:\n",
        "   #    datapath = \"~/scratch/CERN_anglegan/dataset/Ele_VarAngleMeas_100_200_0*.h5\"\n",
        "   datafiles = GetDataFiles(datapath, particle, 1)\n",
        "   print(\"@@@@@ : \", len(datafiles))\n",
        "   data = datafiles[-1] # use the last file for the plots\n",
        "   X, Y, angle, f = GetAngleData(data, angtype='theta', num_events=numevents)\n",
        "\n",
        "   X = np.squeeze(X)/dscale # convert data to GeV\n",
        "   print(\"X reshape at begining \", X.shape)\n",
        "   # X should not be resized but the generated dataset, this is temperary\n",
        "   #X = resize(X,64)\n",
        "   #X = np.moveaxis(X, 1,3)\n",
        "   print(\"X reshape at begining \", X.shape)\n",
        "   #get shape\n",
        "   x = X.shape[1]\n",
        "   y = X.shape[2]\n",
        "   z = X.shape[3]\n",
        "\n",
        "   #select events with significant energy deposition\n",
        "   xsum = np.sum(X, axis=(1, 2, 3))\n",
        "   indexes = np.where(xsum > (0.2))\n",
        "   X=X[indexes]\n",
        "   Y = Y[indexes]\n",
        "   angle = angle[indexes]\n",
        "\n",
        "   num_events = X.shape[0] # number of events can be reduced due to selection\n",
        "\n",
        "   images =[]\n",
        "   gm=importlib.import_module(f'networks.pgan.generator').generator\n",
        "\n",
        "   sess = get_session()\n",
        "   #saver = tf.train.Saver()\n",
        "   print('******** ROOT DEBUG *******', f)\n",
        "   saver = tf.compat.v1.train.import_meta_graph('/content/drive/MyDrive/code/cern/model/model_5_ckpt_5120000.meta')\n",
        "   #saver = tf.train.import_meta_graph('/home/achaibi/scratch/applications/cern/runs8/runs/pgan/2020-11-10_09:57:44/model_4.meta')\n",
        "   #saver = tf.train.import_meta_graph( os.path.join(gweights,'model_4_ckpt_4160000.meta'))\n",
        "   #saver.restore(sess, os.path.join(args.continue_path)\n",
        "   saver.restore(sess, tf.train.latest_checkpoint(\"/content/drive/MyDrive/code/cern/model/\"))\n",
        "   angle = angle\n",
        "   generator = importlib.import_module(f'networks.pgan.generator').generator\n",
        "    \n",
        "   print(\"X SHAPE ####### \", X.shape) \n",
        "   print(\"Y SHAPE ####### \", Y.shape) \n",
        "   X=X[:32]\n",
        "   Y=Y[:32]\n",
        "   angle=angle[:32]\n",
        "   images.append(generate2(generator, 32, [Y/100., angle], latent=latent, concat=2))\n",
        "   images[0] = np.power(images[0], 1./xpower)\n",
        "   \n",
        "   \n",
        "   print(f\"ANGLEPGAN DEBUG ### : images={images}\")\n",
        "   #images = tf.transpose(images, [0, 1, 5, 4, 3, 2])\n",
        "   \n",
        "   numpy_images = []\n",
        "   for i, imgs in enumerate(images):\n",
        "\n",
        "      with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        #test = gsf.eval()\n",
        "        #imgs = tf.squeeze(imgs,[1])\n",
        "        #imgs = tf.transpose(imgs, [0,4,2,3,1])\n",
        "        imgs = sess.run(imgs)\n",
        "        imgs = restore_pic(imgs, 64)\n",
        "        numpy_images.append(imgs)\n",
        "\n",
        "   plotSF(X, numpy_images, Y, labels, out_file=outdir +'/SamplingFraction', session=sess, error=error, stest=stest, ifC=C,grid=grid,leg=leg)\n",
        "   plotshapes(X, numpy_images, x, y, z, Y, out_file=outdir +'/ShowerShapes',labels=labels, log=0, stest=stest, error=error, norm=norm, ifC=C, grid=grid, leg=leg)\n",
        "   plotshapes(X, numpy_images, x, y, z, Y, out_file=outdir +'/ShowerShapes_log',labels=labels, log=1, stest=stest, error=error, norm=norm, ifC=C, grid=grid, leg=leg)\n",
        "   print('The plots are saved in {}'.format(outdir))\n",
        "\n",
        "#Plotting sampling fraction vs. Ep\n",
        "def plotSF(Data, gan_images, Y, labels, out_file, session, error=0, stest=0, ifC=0, grid=0, leg=1, ):\n",
        "   c=ROOT.TCanvas(\"c\" ,\"Sampling Fraction vs. Primary energy\" ,200 ,10 ,700 ,500) #make nice\n",
        "   if grid: c.SetGrid()\n",
        "   color =2\n",
        "   ROOT.gStyle.SetOptStat(0)\n",
        "   Eprof = ROOT.TProfile(\"Eprof\", \"Ratio of Ecal and Ep;Ep;Ecal/Ep\", 100, 0, 500)\n",
        "   dsum = np.sum(Data, axis=(1,2, 3))\n",
        "   print(\"dsum shape :::\", dsum.shape)\n",
        "   dsf = dsum/Y\n",
        "   for j in np.arange(Y.shape[0]):\n",
        "     Eprof.Fill( Y[j], dsf[j])\n",
        "   Eprof.SetTitle(\"Sampling Fraction (cell energy sum / primary particle energy)\")\n",
        "   Eprof.GetXaxis().SetTitle(\"Primary particle energy [GeV]\")\n",
        "   Eprof.GetYaxis().SetTitle(\"Sampling Fraction\")\n",
        "   Eprof.GetYaxis().SetRangeUser(0.01, 0.03)\n",
        "   Eprof.SetLineColor(color)\n",
        "   Eprof.Draw()\n",
        "   if stest:\n",
        "     legend = ROOT.TLegend(0.6, 0.11, 0.89, 0.4)\n",
        "   else:\n",
        "     legend = ROOT.TLegend(0.7, 0.11, 0.89, 0.3)\n",
        "   legend.AddEntry(Eprof, \"Data\", \"l\")\n",
        "   legend.SetBorderSize(0)\n",
        "   Gprof = []\n",
        "   for i, images in enumerate(gan_images):\n",
        "      Gprof.append( ROOT.TProfile(\"Gprof\" +str(i), \"Gprof\" + str(i), 100, 0, 500))\n",
        "      gsum = np.sum(images, axis=(1, 2, 3))\n",
        "      gsf = gsum/Y\n",
        "\n",
        "      for j in range(Y.shape[0]):\n",
        "        Gprof[i].Fill(Y[j], gsf[j])\n",
        "      color = color + 2\n",
        "      Gprof[i].SetLineColor(color)\n",
        "      Gprof[i].Draw('sames')\n",
        "      c.Modified()\n",
        "      sf_error = np.absolute((dsf-gsf)/dsf)\n",
        "      glabel = 'GAN {}'.format(labels[i])\n",
        "      if error:\n",
        "         glabel = glabel + ' MRE={:.4f}'.format(np.mean(sf_error))\n",
        "      legend.AddEntry(Gprof[i], glabel, \"l\")\n",
        "      if stest:\n",
        "         ks = Eprof.KolmogorovTest(Gprof[i], 'WW')\n",
        "         legend.AddEntry(Gprof[i], 'k={:e}'.format(ks), \"l\")\n",
        "      if leg: legend.Draw()\n",
        "      c.Update()\n",
        "   c.Print(out_file+'.pdf')\n",
        "   if ifC:\n",
        "      c.Print(out_file+'.C')\n",
        "\n",
        "# plotting shower shapes\n",
        "def plotshapes(X, generated_images, x, y, z, energy, out_file, labels, log=0, p=[2, 500], norm=0, ifC=0, stest=0, error=0, grid=0, leg=1):\n",
        "   canvas = ROOT.TCanvas(\"canvas\" ,\"\" ,200 ,10 ,700 ,500) #make\n",
        "   canvas.SetTitle('Weighted Histogram for energy deposition along x, y, z axis')\n",
        "   if grid: canvas.SetGrid()\n",
        "   color = 2\n",
        "   canvas.Divide(2,2)\n",
        "   print(\"IMAGE X &&&&&&& :\", X.shape)\n",
        "   # THIS IS TEMPORARY! the generated image should have the same shape as the real images and not the contrary\n",
        "   array1x = np.sum(X, axis=(2,3))\n",
        "   array1y = np.sum(X, axis=(1,3))\n",
        "   array1z = np.sum(X, axis=(1,2))\n",
        "   if stest:\n",
        "     leg = ROOT.TLegend(0.1,0.1,0.9,0.9)\n",
        "   else:\n",
        "     leg = ROOT.TLegend(0.1,0.4,0.9,0.9)\n",
        "   #leg.SetTextSize(0.06)\n",
        "   h1x = ROOT.TH1F('G4x' + str(energy), '', x, 0, x)\n",
        "   h1y = ROOT.TH1F('G4y' + str(energy), '', y, 0, y)\n",
        "   h1z = ROOT.TH1F('G4z' + str(energy), '', z, 0, z)\n",
        "   h1x.Sumw2()\n",
        "   h1y.Sumw2()\n",
        "   h1z.Sumw2()\n",
        "   h1x.SetLineColor(color)\n",
        "   h1y.SetLineColor(color)\n",
        "   h1z.SetLineColor(color)\n",
        "   color+=2\n",
        "   canvas.cd(1)\n",
        "   if log:\n",
        "      ROOT.gPad.SetLogy()\n",
        "   my.fill_hist_wt(h1x, array1x)\n",
        "   if norm: h1x=my.normalize(h1x)\n",
        "   h1x.Draw()\n",
        "   h1x.Draw('sames hist')\n",
        "   h1x.GetXaxis().SetTitle(\"Energy deposition along x axis\")\n",
        "   leg.AddEntry(h1x, 'G4',\"l\")\n",
        "   canvas.cd(2)\n",
        "   if log:\n",
        "      ROOT.gPad.SetLogy()\n",
        "   my.fill_hist_wt(h1y, array1y)\n",
        "   if norm: h1y=my.normalize(h1y)\n",
        "   h1y.Draw()\n",
        "   h1y.Draw('sames hist')\n",
        "   h1y.GetXaxis().SetTitle(\"Energy deposition along y axis\")\n",
        "   canvas.cd(3)\n",
        "   if log:\n",
        "      ROOT.gPad.SetLogy()\n",
        "   my.fill_hist_wt(h1z, array1z)\n",
        "   if norm : h1z=my.normalize(h1z)\n",
        "   h1z.Draw()\n",
        "   h1z.Draw('sames hist')\n",
        "   h1z.GetXaxis().SetTitle(\"Energy deposition along z axis\")\n",
        "   canvas.cd(4)\n",
        "   canvas.Update()\n",
        "   h2xs=[]\n",
        "   h2ys=[]\n",
        "   h2zs=[]\n",
        "   for i, images in enumerate(generated_images):\n",
        "      array2x = np.sum(images, axis=(2,3))\n",
        "      #array2x = tf.reduce_sum(images, axis=(2,3))\n",
        "      array2y = np.sum(images, axis=(1,3))\n",
        "      #array2y = tf.reduce_sum(images, axis=(1,3))\n",
        "      array2z = np.sum(images, axis=(1,2))\n",
        "      #array2z = tf.reduce_sum(images, axis=(1,2))\n",
        "      errorx = np.divide(np.absolute(array1x-array2x), array1x, out=np.zeros_like(array1x), where=array1x!=0)\n",
        "      errory = np.divide(np.absolute(array1y-array2y), array1y, out=np.zeros_like(array1y), where=array1y!=0)\n",
        "      errorz = np.divide(np.absolute(array1z-array2z), array1z, out=np.zeros_like(array1z), where=array1z!=0)\n",
        "\n",
        "      h2xs.append(ROOT.TH1F('GANx' + str(energy)+ labels[i], '', x, 0, x))\n",
        "      h2ys.append(ROOT.TH1F('GANy' + str(energy)+ labels[i], '', y, 0, y))\n",
        "      h2zs.append(ROOT.TH1F('GANz' + str(energy)+ labels[i], '', z, 0, z))\n",
        "      h2x=h2xs[i]\n",
        "      h2y=h2ys[i]\n",
        "      h2z=h2zs[i]\n",
        "      h2x.Sumw2()\n",
        "      h2y.Sumw2()\n",
        "      h2z.Sumw2()\n",
        "\n",
        "      h2x.SetLineColor(color)\n",
        "      h2y.SetLineColor(color)\n",
        "      h2z.SetLineColor(color)\n",
        "      canvas.cd(1)\n",
        "      my.fill_hist_wt(h2x, array2x)\n",
        "      if norm: h2x=my.normalize(h2x)\n",
        "      h2x.Draw('sames')\n",
        "      h2x.Draw('sames hist')\n",
        "      canvas.Update()\n",
        "      #my.stat_pos(h2x)\n",
        "      if stest:\n",
        "         res=np.array\n",
        "         ks= h1x.KolmogorovTest(h2x, 'WW')\n",
        "         glabel = \"GAN {} X axis k= {:e}\".format(labels[i], ks)\n",
        "         leg.AddEntry(h2x, glabel,\"l\")\n",
        "      canvas.Update()\n",
        "      canvas.cd(2)\n",
        "      my.fill_hist_wt(h2y, array2y)\n",
        "      if norm: h2y=my.normalize(h2y)\n",
        "      h2y.Draw('sames')\n",
        "      h2y.Draw('sames hist')\n",
        "      canvas.Update()\n",
        "      #my.stat_pos(h2y)\n",
        "      if stest:\n",
        "         ks= h1y.KolmogorovTest(h2y, 'WW')\n",
        "         glabel = \"GAN {} Y axis k= {:e}\".format(labels[i], ks)\n",
        "         leg.AddEntry(h2y, glabel,\"l\")\n",
        "      canvas.Update()\n",
        "      canvas.cd(3)\n",
        "      my.fill_hist_wt(h2z, array2z)\n",
        "      if norm: h2z=my.normalize(h2z)\n",
        "      h2z.Draw('sames')\n",
        "      h2z.Draw('sames hist')\n",
        "      canvas.Update()\n",
        "      #my.stat_pos(h2z)\n",
        "      canvas.Update()\n",
        "      if stest:\n",
        "         ks= h1z.KolmogorovTest(h2z, 'WW')\n",
        "         glabel = \"GAN {} Z axis k= {:e}\".format(labels[i], ks)\n",
        "         leg.AddEntry(h2z, glabel,\"l\")\n",
        "      canvas.Update()\n",
        "      color+=2\n",
        "   canvas.Update()\n",
        "   canvas.cd(4)\n",
        "   leg.SetHeader(\"Energy deposited along x, y, z axis\", \"C\")\n",
        "\n",
        "   for i, h in enumerate(h2xs):\n",
        "       glabel = 'GAN ' + labels[i]\n",
        "       if error:\n",
        "          tot_error = (np.mean(errorx) + np.mean(errory) + np.mean(errorz))/3.\n",
        "          glabel = glabel + ' MRE {:.4f}'.format(np.mean(errorz))\n",
        "       elif not stest:\n",
        "          leg.AddEntry(h, glabel,\"l\")\n",
        "   if leg: leg.Draw()\n",
        "   canvas.Update()\n",
        "   canvas.Print(out_file + '.pdf')\n",
        "   if ifC:\n",
        "      canvas.Print(out_file + '.C')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "   main()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Searching in : /content/drive/MyDrive/dataset/cern/Ele_VarAngleMeas_100_200_000.h5\n",
            "Found 1 files. \n",
            "@@@@@ :  1\n",
            "Loading Data from ..... /content/drive/MyDrive/dataset/cern/Ele_VarAngleMeas_100_200_000.h5\n",
            "X reshape at begining  (5000, 51, 51, 25)\n",
            "X reshape at begining  (5000, 51, 51, 25)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-50d2c6716356>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m    \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-50d2c6716356>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m    \u001b[0mgm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'networks.pgan.generator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m    \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m    \u001b[0;31m#saver = tf.train.Saver()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'******** ROOT DEBUG *******'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-50d2c6716356>\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mgopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplace_pruned_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_soft_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewrite_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewriter_config_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRewriterConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOFF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'GraphOptions'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Nkq6TxSDj39",
        "outputId": "a75f0603-8c2d-417f-9aa0-2924b5fecb3c"
      },
      "source": [
        "!git push origin adel/pgan"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: could not read Password for 'https://{708e5c851440f2d63bc52cbda896495c250f3267}@github.com': No such device or address\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGkc5s0iG_ZK",
        "outputId": "24fb194b-54bd-4739-aecc-226c3d922daf"
      },
      "source": [
        "# Clone github repository setup\n",
        "# import join used to join ROOT path and MY_GOOGLE_DRIVE_PATH\n",
        "from os.path import join  \n",
        "\n",
        "# path to your project on Google Drive\n",
        "MY_GOOGLE_DRIVE_PATH = \"/content/drive/MyDrive/code/\"\n",
        "# replace with your Github username \n",
        "GIT_USERNAME = \"adelc\" \n",
        "# definitely replace with your\n",
        "GIT_TOKEN = \"708e5c851440f2d63bc52cbda896495c250f3267\"  \n",
        "# Replace with your github repository in this case we want \n",
        "# to clone deep-learning-v2-pytorch repository\n",
        "GIT_REPOSITORY = \"3Dgan\" \n",
        "\n",
        "PROJECT_PATH = join(\"/\", MY_GOOGLE_DRIVE_PATH)\n",
        "\n",
        "# It's good to print out the value if you are not sure \n",
        "print(\"PROJECT_PATH: \", PROJECT_PATH) \n",
        "\n",
        "# In case we haven't created the folder already; we will create a folder in the project path \n",
        "#!mkdir \"cern\"    \n",
        "\n",
        "#GIT_PATH = \"https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPOSITORY}.git\" this return 400 Bad Request for me\n",
        "GIT_PATH = \"https://\" + GIT_TOKEN + \"@github.com/\" + GIT_USERNAME + \"/\" + GIT_REPOSITORY + \".git\"\n",
        "print(\"GIT_PATH: \", GIT_PATH)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PROJECT_PATH:  /content/drive/MyDrive/code/\n",
            "GIT_PATH:  https://708e5c851440f2d63bc52cbda896495c250f3267@github.com/adelc/3Dgan.git\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eL6eYqlIjG7",
        "outputId": "c98b11b0-e59e-43b4-a0d6-d8de61a3a26b"
      },
      "source": [
        "!git push origin adel/pgan"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: could not read Password for 'https://{708e5c851440f2d63bc52cbda896495c250f3267}@github.com': No such device or address\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}