{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "plots.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adelC/3Dgan/blob/adel%2Fpgan/ipynb/plots.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJTJhvSWp3uZ"
      },
      "source": [
        "## Environement setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Yv4nljvqCK7",
        "outputId": "f6ca7ccd-a932-4910-e49b-65d04fcfab30"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBQU_Basp0aa",
        "outputId": "eee9b352-5620-4dce-f3d9-229dbb03543d"
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFmpU3sbdr2Z"
      },
      "source": [
        "## Loading Google Drive and mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVsG4Ox9Zc_0",
        "outputId": "2c2c447c-5f32-41bd-c0d2-4383038ed19c"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7VCQigqdoOA"
      },
      "source": [
        "## Setting ROOT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0MDcSPdbjbj"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/My Drive/tools/root/\")\n",
        "sys.path.append(\"/content/drive/My Drive/tools/root/bin/\")\n",
        "sys.path.append(\"/content/drive/My Drive/tools/root/include/\")\n",
        "sys.path.append(\"/content/drive/My Drive/tools/root/lib/\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxxTcYDGdd5y"
      },
      "source": [
        "import ROOT"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHhBPvGctRN1",
        "outputId": "1d3591b1-95a3-471c-d3fb-7c10e943e224"
      },
      "source": [
        "%cd /content/drive/MyDrive/code/cern/3Dgan/"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/code/cern/3Dgan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "OlM2Cd5ita8D",
        "outputId": "df2a5e94-cb83-4e52-e755-7bdec586d1e9"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "from os import path\n",
        "import argparse\n",
        "import h5py\n",
        "import ROOT\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "#import keras.backend as K\n",
        "#import horovod.tensorflow as hvd\n",
        "from scripts.GANutils import GetData, GetAngleData, GetDataFiles, generate, generate2,  safe_mkdir\n",
        "from scripts.hdf_to_numpy import resize, restore_pic\n",
        "import scripts.ROOTutils as my\n",
        "from tensorflow.core.protobuf import rewriter_config_pb2\n",
        "import time\n",
        "import importlib\n",
        "sys.path.insert(0,'../')\n",
        "try:\n",
        "    import setGPU #if Caltech\n",
        "except:\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_parser():\n",
        "   # To parse the input parameters to the script\n",
        "   parser = argparse.ArgumentParser()\n",
        "   parser.add_argument('--gweights', type=str, nargs='+', default=['../weights/3dgan_weights_gan_training_epsilon_2_500GeV/params_generator_epoch_021.hdf5'], help=\"Complete PATH to the trained weights to test with hdf5 extension\")\n",
        "   parser.add_argument('--ang', default=1, type=int, help=\"If using angle vefsion\")\n",
        "   parser.add_argument('--pgan', type=int, default=1, help='If using PGAN')\n",
        "   parser.add_argument('--particle', default='Ele', type=str, help=\"particle type\")\n",
        "   parser.add_argument('--labels', type=str, nargs='+', default=[''], help=\"labels for different weights\")\n",
        "   parser.add_argument('--xscales',  type=float, nargs='+', help=\"scaling factor for cell energies\")\n",
        "   parser.add_argument('--datapath', default='full2', help='Data to check the output obtained')\n",
        "   parser.add_argument('--outdir', default= 'results/short_analysis', help='Complete PATH to save the output plot')\n",
        "   parser.add_argument('--numevents', action='store', type=int, default=10000, help='Max limit for events used for validation')\n",
        "   parser.add_argument('--latent', action='store', type=int, help='size of latent space to sample')\n",
        "   parser.add_argument('--dformat', action='store', type=str, default='channels_last', help='keras image format')\n",
        "   parser.add_argument('--error', type=int, default=0, help='add relative errors to plots')\n",
        "   parser.add_argument('--stest', type=int, default=0, help='add ktest to plots')\n",
        "   parser.add_argument('--norm', type=int, default=1, help='normalize shower shapes')\n",
        "   parser.add_argument('--ifC', type=int, default=0, help='generate .C files')\n",
        "   parser.add_argument('--leg', type=int, default=1, help='draw legend')\n",
        "   parser.add_argument('--grid', type=int, default=0, help='draw grid')\n",
        "   return parser\n",
        "\n",
        "\n",
        "def get_session():\n",
        "    gopts = tf.GraphOptions(place_pruned_graph=True)\n",
        "    config = tf.ConfigProto(graph_options=gopts, allow_soft_placement=True)\n",
        "    config.graph_options.rewrite_options.layout_optimizer = rewriter_config_pb2.RewriterConfig.OFF\n",
        "    sess = tf.Session(config=config)\n",
        "    return sess\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "   #parser = get_parser()\n",
        "   #args = parser.parse_args()\n",
        "   #gweights = args.gweights if isinstance(args.gweights, list) else [args.gweights]\n",
        "   #labels = args.labels if isinstance(args.labels, list) else [args.labels]\n",
        "   ang = 1 #args.ang\n",
        "   pgan = 1 #args.pgan\n",
        "   particle = \"Ele\" #args.particle\n",
        "   latent = 256 # args.latent\n",
        "   datapath = \"/content/drive/MyDrive/dataset/cern/Ele_VarAngleMeas_100_200_000.h5\" #args.datapath\n",
        "   outdir = \"output\"#args.outdir\n",
        "   numevents= 10000 #args.numevents\n",
        "   dformat= \"channels_last\" #args.dformat\n",
        "   error = 0 #args.error\n",
        "   stest = 0 #args.stest\n",
        "   norm = 1 #args.norm\n",
        "   C = 0 #args.ifC\n",
        "   leg = 1 #args.leg\n",
        "   grid = 0 #args.grid\n",
        "   xscales = 1.\n",
        "   if xscales:\n",
        "     xscales = xscales if isinstance(xscales, list) else [xscales]\n",
        "   safe_mkdir(outdir)\n",
        "   print('{} dir created'.format(outdir))\n",
        "   K.set_image_data_format(dformat)\n",
        "\n",
        "   dscale = 50.\n",
        "   if not latent:\n",
        "       latent = 256\n",
        "   if not xscales:\n",
        "       xscales = [1] * len(gweights)\n",
        "   xpower = 0.85\n",
        "  \n",
        "#   if datapath=='reduced':\n",
        "#       datapath = \"/storage/group/gpu/bigdata/gkhattak/*Measured3ThetaEscan/*.h5\"  # Data path 100-200 GeV\n",
        "#   elif datapath=='full':\n",
        "#       datapath = \"/storage/group/gpu/bigdata/LCDLargeWindow/LCDLargeWindow/varangle/*scan/*scan_RandomAngle_*.h5\" # culture plate\n",
        "#   else:\n",
        "#       datapath = \"~/scratch/CERN_anglegan/dataset/Ele_VarAngleMeas_100_200_0*.h5\"\n",
        "\n",
        "   datafiles = GetDataFiles(datapath, particle, 1)\n",
        "   print(\"@@@@@ : \", len(datafiles))\n",
        "   #data = datafiles[-1] # use the last file for the plots\n",
        "   data = datafiles[0] # use the last file for the plots\n",
        "   X, Y, angle, f = GetAngleData(data, angtype='theta', num_events=numevents)\n",
        "\n",
        "   X = np.squeeze(X)/dscale # convert data to GeV\n",
        "   print(\"X reshape at begining \", X.shape)\n",
        "   # X should not be resized but the generated dataset, this is temperary\n",
        "   #X = resize(X,64)\n",
        "   #X = np.moveaxis(X, 1,3)\n",
        "   print(\"X reshape at begining \", X.shape)\n",
        "   #get shape\n",
        "   x = X.shape[1]\n",
        "   y = X.shape[2]\n",
        "   z = X.shape[3]\n",
        "\n",
        "   #select events with significant energy deposition\n",
        "   xsum = np.sum(X, axis=(1, 2, 3))\n",
        "   indexes = np.where(xsum > (0.2))\n",
        "   X=X[indexes]\n",
        "   Y = Y[indexes]\n",
        "   angle = angle[indexes]\n",
        "\n",
        "   num_events = X.shape[0] # number of events can be reduced due to selection\n",
        "\n",
        "   images =[]\n",
        "   gm=importlib.import_module(f'networks.pgan.generator').generator\n",
        "\n",
        "   sess = get_session()\n",
        "   #saver = tf.train.Saver()\n",
        "   print('******** ROOT DEBUG *******', f)\n",
        "   saver = tf.compat.v1.train.import_meta_graph('/home/achaibi/scratch/applications/cern/runs10/runs/pgan/weights/model_5.meta')\n",
        "   #saver = tf.train.import_meta_graph('/home/achaibi/scratch/applications/cern/runs8/runs/pgan/2020-11-10_09:57:44/model_4.meta')\n",
        "   #saver = tf.train.import_meta_graph( os.path.join(gweights,'model_4_ckpt_4160000.meta'))\n",
        "   #saver.restore(sess, os.path.join(args.continue_path)\n",
        "   saver.restore(sess, tf.train.latest_checkpoint(\"/home/achaibi/scratch/applications/cern/runs10/runs/pgan/weights/\"))\n",
        "   angle = angle\n",
        "   generator = importlib.import_module(f'networks.pgan.generator').generator\n",
        "    \n",
        "   print(\"X SHAPE ####### \", X.shape) \n",
        "   print(\"Y SHAPE ####### \", Y.shape) \n",
        "   X=X[:32]\n",
        "   Y=Y[:32]\n",
        "   angle=angle[:32]\n",
        "   images.append(generate2(generator, 32, [Y/100., angle], latent=latent, concat=2))\n",
        "   images[0] = np.power(images[0], 1./xpower)\n",
        "   \n",
        "   \n",
        "   print(f\"ANGLEPGAN DEBUG ### : images={images}\")\n",
        "   #images = tf.transpose(images, [0, 1, 5, 4, 3, 2])\n",
        "   \n",
        "   numpy_images = []\n",
        "   for i, imgs in enumerate(images):\n",
        "\n",
        "      with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        #test = gsf.eval()\n",
        "        #imgs = tf.squeeze(imgs,[1])\n",
        "        #imgs = tf.transpose(imgs, [0,4,2,3,1])\n",
        "        imgs = sess.run(imgs)\n",
        "        imgs = restore_pic(imgs, 64)\n",
        "        numpy_images.append(imgs)\n",
        "\n",
        "   plotSF(X, numpy_images, Y, labels, out_file=outdir +'/SamplingFraction', session=sess, error=error, stest=stest, ifC=C,grid=grid,leg=leg)\n",
        "   plotshapes(X, numpy_images, x, y, z, Y, out_file=outdir +'/ShowerShapes',labels=labels, log=0, stest=stest, error=error, norm=norm, ifC=C, grid=grid, leg=leg)\n",
        "   plotshapes(X, numpy_images, x, y, z, Y, out_file=outdir +'/ShowerShapes_log',labels=labels, log=1, stest=stest, error=error, norm=norm, ifC=C, grid=grid, leg=leg)\n",
        "   print('The plots are saved in {}'.format(outdir))\n",
        "\n",
        "#Plotting sampling fraction vs. Ep\n",
        "def plotSF(Data, gan_images, Y, labels, out_file, session, error=0, stest=0, ifC=0, grid=0, leg=1, ):\n",
        "   c=ROOT.TCanvas(\"c\" ,\"Sampling Fraction vs. Primary energy\" ,200 ,10 ,700 ,500) #make nice\n",
        "   if grid: c.SetGrid()\n",
        "   color =2\n",
        "   ROOT.gStyle.SetOptStat(0)\n",
        "   Eprof = ROOT.TProfile(\"Eprof\", \"Ratio of Ecal and Ep;Ep;Ecal/Ep\", 100, 0, 500)\n",
        "   dsum = np.sum(Data, axis=(1,2, 3))\n",
        "   print(\"dsum shape :::\", dsum.shape)\n",
        "   dsf = dsum/Y\n",
        "   for j in np.arange(Y.shape[0]):\n",
        "     Eprof.Fill( Y[j], dsf[j])\n",
        "   Eprof.SetTitle(\"Sampling Fraction (cell energy sum / primary particle energy)\")\n",
        "   Eprof.GetXaxis().SetTitle(\"Primary particle energy [GeV]\")\n",
        "   Eprof.GetYaxis().SetTitle(\"Sampling Fraction\")\n",
        "   Eprof.GetYaxis().SetRangeUser(0.01, 0.03)\n",
        "   Eprof.SetLineColor(color)\n",
        "   Eprof.Draw()\n",
        "   if stest:\n",
        "     legend = ROOT.TLegend(0.6, 0.11, 0.89, 0.4)\n",
        "   else:\n",
        "     legend = ROOT.TLegend(0.7, 0.11, 0.89, 0.3)\n",
        "   legend.AddEntry(Eprof, \"Data\", \"l\")\n",
        "   legend.SetBorderSize(0)\n",
        "   Gprof = []\n",
        "   for i, images in enumerate(gan_images):\n",
        "      Gprof.append( ROOT.TProfile(\"Gprof\" +str(i), \"Gprof\" + str(i), 100, 0, 500))\n",
        "      gsum = np.sum(images, axis=(1, 2, 3))\n",
        "      gsf = gsum/Y\n",
        "\n",
        "      for j in range(Y.shape[0]):\n",
        "        Gprof[i].Fill(Y[j], gsf[j])\n",
        "      color = color + 2\n",
        "      Gprof[i].SetLineColor(color)\n",
        "      Gprof[i].Draw('sames')\n",
        "      c.Modified()\n",
        "      sf_error = np.absolute((dsf-gsf)/dsf)\n",
        "      glabel = 'GAN {}'.format(labels[i])\n",
        "      if error:\n",
        "         glabel = glabel + ' MRE={:.4f}'.format(np.mean(sf_error))\n",
        "      legend.AddEntry(Gprof[i], glabel, \"l\")\n",
        "      if stest:\n",
        "         ks = Eprof.KolmogorovTest(Gprof[i], 'WW')\n",
        "         legend.AddEntry(Gprof[i], 'k={:e}'.format(ks), \"l\")\n",
        "      if leg: legend.Draw()\n",
        "      c.Update()\n",
        "   c.Print(out_file+'.pdf')\n",
        "   if ifC:\n",
        "      c.Print(out_file+'.C')\n",
        "\n",
        "# plotting shower shapes\n",
        "def plotshapes(X, generated_images, x, y, z, energy, out_file, labels, log=0, p=[2, 500], norm=0, ifC=0, stest=0, error=0, grid=0, leg=1):\n",
        "   canvas = ROOT.TCanvas(\"canvas\" ,\"\" ,200 ,10 ,700 ,500) #make\n",
        "   canvas.SetTitle('Weighted Histogram for energy deposition along x, y, z axis')\n",
        "   if grid: canvas.SetGrid()\n",
        "   color = 2\n",
        "   canvas.Divide(2,2)\n",
        "   print(\"IMAGE X &&&&&&& :\", X.shape)\n",
        "   # THIS IS TEMPORARY! the generated image should have the same shape as the real images and not the contrary\n",
        "   array1x = np.sum(X, axis=(2,3))\n",
        "   array1y = np.sum(X, axis=(1,3))\n",
        "   array1z = np.sum(X, axis=(1,2))\n",
        "   if stest:\n",
        "     leg = ROOT.TLegend(0.1,0.1,0.9,0.9)\n",
        "   else:\n",
        "     leg = ROOT.TLegend(0.1,0.4,0.9,0.9)\n",
        "   #leg.SetTextSize(0.06)\n",
        "   h1x = ROOT.TH1F('G4x' + str(energy), '', x, 0, x)\n",
        "   h1y = ROOT.TH1F('G4y' + str(energy), '', y, 0, y)\n",
        "   h1z = ROOT.TH1F('G4z' + str(energy), '', z, 0, z)\n",
        "   h1x.Sumw2()\n",
        "   h1y.Sumw2()\n",
        "   h1z.Sumw2()\n",
        "   h1x.SetLineColor(color)\n",
        "   h1y.SetLineColor(color)\n",
        "   h1z.SetLineColor(color)\n",
        "   color+=2\n",
        "   canvas.cd(1)\n",
        "   if log:\n",
        "      ROOT.gPad.SetLogy()\n",
        "   my.fill_hist_wt(h1x, array1x)\n",
        "   if norm: h1x=my.normalize(h1x)\n",
        "   h1x.Draw()\n",
        "   h1x.Draw('sames hist')\n",
        "   h1x.GetXaxis().SetTitle(\"Energy deposition along x axis\")\n",
        "   leg.AddEntry(h1x, 'G4',\"l\")\n",
        "   canvas.cd(2)\n",
        "   if log:\n",
        "      ROOT.gPad.SetLogy()\n",
        "   my.fill_hist_wt(h1y, array1y)\n",
        "   if norm: h1y=my.normalize(h1y)\n",
        "   h1y.Draw()\n",
        "   h1y.Draw('sames hist')\n",
        "   h1y.GetXaxis().SetTitle(\"Energy deposition along y axis\")\n",
        "   canvas.cd(3)\n",
        "   if log:\n",
        "      ROOT.gPad.SetLogy()\n",
        "   my.fill_hist_wt(h1z, array1z)\n",
        "   if norm : h1z=my.normalize(h1z)\n",
        "   h1z.Draw()\n",
        "   h1z.Draw('sames hist')\n",
        "   h1z.GetXaxis().SetTitle(\"Energy deposition along z axis\")\n",
        "   canvas.cd(4)\n",
        "   canvas.Update()\n",
        "   h2xs=[]\n",
        "   h2ys=[]\n",
        "   h2zs=[]\n",
        "   for i, images in enumerate(generated_images):\n",
        "      array2x = np.sum(images, axis=(2,3))\n",
        "      #array2x = tf.reduce_sum(images, axis=(2,3))\n",
        "      array2y = np.sum(images, axis=(1,3))\n",
        "      #array2y = tf.reduce_sum(images, axis=(1,3))\n",
        "      array2z = np.sum(images, axis=(1,2))\n",
        "      #array2z = tf.reduce_sum(images, axis=(1,2))\n",
        "      errorx = np.divide(np.absolute(array1x-array2x), array1x, out=np.zeros_like(array1x), where=array1x!=0)\n",
        "      errory = np.divide(np.absolute(array1y-array2y), array1y, out=np.zeros_like(array1y), where=array1y!=0)\n",
        "      errorz = np.divide(np.absolute(array1z-array2z), array1z, out=np.zeros_like(array1z), where=array1z!=0)\n",
        "\n",
        "      h2xs.append(ROOT.TH1F('GANx' + str(energy)+ labels[i], '', x, 0, x))\n",
        "      h2ys.append(ROOT.TH1F('GANy' + str(energy)+ labels[i], '', y, 0, y))\n",
        "      h2zs.append(ROOT.TH1F('GANz' + str(energy)+ labels[i], '', z, 0, z))\n",
        "      h2x=h2xs[i]\n",
        "      h2y=h2ys[i]\n",
        "      h2z=h2zs[i]\n",
        "      h2x.Sumw2()\n",
        "      h2y.Sumw2()\n",
        "      h2z.Sumw2()\n",
        "\n",
        "      h2x.SetLineColor(color)\n",
        "      h2y.SetLineColor(color)\n",
        "      h2z.SetLineColor(color)\n",
        "      canvas.cd(1)\n",
        "      my.fill_hist_wt(h2x, array2x)\n",
        "      if norm: h2x=my.normalize(h2x)\n",
        "      h2x.Draw('sames')\n",
        "      h2x.Draw('sames hist')\n",
        "      canvas.Update()\n",
        "      #my.stat_pos(h2x)\n",
        "      if stest:\n",
        "         res=np.array\n",
        "         ks= h1x.KolmogorovTest(h2x, 'WW')\n",
        "         glabel = \"GAN {} X axis k= {:e}\".format(labels[i], ks)\n",
        "         leg.AddEntry(h2x, glabel,\"l\")\n",
        "      canvas.Update()\n",
        "      canvas.cd(2)\n",
        "      my.fill_hist_wt(h2y, array2y)\n",
        "      if norm: h2y=my.normalize(h2y)\n",
        "      h2y.Draw('sames')\n",
        "      h2y.Draw('sames hist')\n",
        "      canvas.Update()\n",
        "      #my.stat_pos(h2y)\n",
        "      if stest:\n",
        "         ks= h1y.KolmogorovTest(h2y, 'WW')\n",
        "         glabel = \"GAN {} Y axis k= {:e}\".format(labels[i], ks)\n",
        "         leg.AddEntry(h2y, glabel,\"l\")\n",
        "      canvas.Update()\n",
        "      canvas.cd(3)\n",
        "      my.fill_hist_wt(h2z, array2z)\n",
        "      if norm: h2z=my.normalize(h2z)\n",
        "      h2z.Draw('sames')\n",
        "      h2z.Draw('sames hist')\n",
        "      canvas.Update()\n",
        "      #my.stat_pos(h2z)\n",
        "      canvas.Update()\n",
        "      if stest:\n",
        "         ks= h1z.KolmogorovTest(h2z, 'WW')\n",
        "         glabel = \"GAN {} Z axis k= {:e}\".format(labels[i], ks)\n",
        "         leg.AddEntry(h2z, glabel,\"l\")\n",
        "      canvas.Update()\n",
        "      color+=2\n",
        "   canvas.Update()\n",
        "   canvas.cd(4)\n",
        "   leg.SetHeader(\"Energy deposited along x, y, z axis\", \"C\")\n",
        "\n",
        "   for i, h in enumerate(h2xs):\n",
        "       glabel = 'GAN ' + labels[i]\n",
        "       if error:\n",
        "          tot_error = (np.mean(errorx) + np.mean(errory) + np.mean(errorz))/3.\n",
        "          glabel = glabel + ' MRE {:.4f}'.format(np.mean(errorz))\n",
        "       elif not stest:\n",
        "          leg.AddEntry(h, glabel,\"l\")\n",
        "   if leg: leg.Draw()\n",
        "   canvas.Update()\n",
        "   canvas.Print(out_file + '.pdf')\n",
        "   if ifC:\n",
        "      canvas.Print(out_file + '.C')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "   main()\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output dir created\n",
            "Searching in : /content/drive/MyDrive/dataset/cern/\n",
            "Found 0 files. \n",
            "@@@@@ :  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-14b4693b328d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m    \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-14b4693b328d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"@@@@@ : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatafiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m    \u001b[0;31m#data = datafiles[-1] # use the last file for the plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m    \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatafiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# use the last file for the plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m    \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetAngleData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'theta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_events\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: string index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfH8dvayzWrc"
      },
      "source": [
        "python plot.py --datapath ~/scratch/CERN_anglegan/dataset/Ele_VarAngleMeas_100_200_000.h5 --ang 1 --outdir res4/ --latent 256 --xscales 1. --gweights ~/scratch/applications/cern/runs21/runs/pgan/2020-12-11_10\\:34\\:11/ --pgan 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}