{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em's Debug File - currently working on concatenating ang and e_p onto latent z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDataAngle(datafile, imgs3dscale =1, imgs3dpower=1, e_pscale = 100, angscale=1, angtype='theta', thresh=1e-4):\n",
    "    print ('Loading Data from .....', datafile)\n",
    "    f = h5py.File(datafile,'r')                    # load data into f variable\n",
    "    ang = np.array(f.get(angtype))                 # ang is an array of angle data from f, one value is concatenated onto the latent vector\n",
    "    imgs3d = np.array(f.get('ECAL'))* imgs3dscale    # imgs3d is a 3d array, cut from the cylinder that the calorimeter produces -has 25 layers along z-axis\n",
    "    e_p = np.array(f.get('energy'))/e_pscale       # e_p is an array of scaled energy data from f, one value is concatenated onto the latent vector\n",
    "    imgs3d[imgs3d < thresh] = 0        # when imgs3d values are less than the threshold, they are reset to 0\n",
    "    \n",
    "    # set imgs3d, e_p, and ang as float 32 datatypes\n",
    "    imgs3d = imgs3d.astype(np.float32)\n",
    "    e_p = e_p.astype(np.float32)\n",
    "    ang = ang.astype(np.float32)\n",
    "    \n",
    "    imgs3d = np.expand_dims(imgs3d, axis=-1)         # insert a new axis at the beginning for imgs3d\n",
    "    \n",
    "    # sum along axis\n",
    "    ecal = np.sum(imgs3d, axis=(1, 2, 3))    # summed imgs3d data, used for training the discriminator\n",
    "     \n",
    "    # imgs3d ^ imgs3dpower\n",
    "    if imgs3dpower !=1.:\n",
    "        imgs3d = np.power(imgs3d, imgs3dpower)\n",
    "            \n",
    "    # imgs3d=ecal data; e_p=energy data; ecal=summed imgs3d (used to train the discriminator); ang=angle data\n",
    "    return imgs3d, e_p, ang, ecal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data from ..... Ele_VarAngleMeas_100_200_005.h5\n"
     ]
    }
   ],
   "source": [
    "imgs3d, e_p, ang, ecal = GetDataAngle('Ele_VarAngleMeas_100_200_005.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_13:0' shape=(256,) dtype=float32>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dim = 256\n",
    "z = tf.random.normal([latent_dim-2])\n",
    "z = tf.concat([z, [e_p[0]], [ang[0]]], 0)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 254)\n",
      "(4, 1)\n",
      "(4, 1)\n",
      "(4, 256)\n",
      "Tensor(\"concat_14:0\", shape=(4, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#z = tf.random.normal(shape=[tf.shape(real_image_input)[0], latent_dim-2])    #shape=[int corresponding to batch_size, 254]\n",
    "z_batch_size = 4                                             #tf.shape(real_image_input)[0]\n",
    "z = tf.random.normal(shape=[z_batch_size, latent_dim-2])   \n",
    "print(z.shape)\n",
    "e_p_vector = e_p[0:(z_batch_size)].reshape(z_batch_size,1)   # need z_batch_size x 1\n",
    "print(e_p_vector.shape)\n",
    "ang_vector = ang[0:(z_batch_size)].reshape(z_batch_size,1)   # need z_batch_size x 1\n",
    "print(ang_vector.shape)\n",
    "z = tf.concat([ z, e_p_vector, ang_vector ], 1)\n",
    "print(z.shape)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss.py concatenation code -- subbed phase and batch_size variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_15:0' shape=(12, 256) dtype=float32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase = 2 #added\n",
    "z_batch_size = 12#tf.shape(real_image_input)[0]                 # this value should be an integer\n",
    "z = tf.random.normal(shape=[z_batch_size, latent_dim-2])   \n",
    "start = (z_batch_size * (phase-1))\n",
    "e_p_vector = e_p[start:(start+z_batch_size)].reshape(z_batch_size,1)   # need z_batch_size x 1\n",
    "ang_vector = ang[start:(start+z_batch_size)].reshape(z_batch_size,1)   # need z_batch_size x 1\n",
    "z = tf.concat([ z, e_p_vector, ang_vector ], 1)    # shape = (z_batch_size, 256)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emma's new code -- take out batch selection (adel just passes the correct batch size in sara_main.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(5000, 1)\n",
      "(5000, 256)\n"
     ]
    }
   ],
   "source": [
    "phase = 2 #added for testing\n",
    "# the batch size will be much smaller in reality, I only put in 5000 for testing because Adel sends in the shortened tensors\n",
    "z_batch_size = 5000#tf.shape(real_image_input)[0]                 # this value should be an integer\n",
    "\n",
    "#Adel is passing e_p and ang as batch sized tensors\n",
    "e_p_tensor = tf.reshape(e_p, [z_batch_size,1])   # need z_batch_size x 1\n",
    "print(e_p_tensor.shape)\n",
    "print(type(e_p_tensor))\n",
    "ang_tensor = tf.reshape(ang, [z_batch_size,1])   # need z_batch_size x 1\n",
    "print(ang_tensor.shape)\n",
    "\n",
    "z = tf.random.normal(shape=[z_batch_size, latent_dim-2])   \n",
    "z = tf.concat([z, e_p_tensor, ang_tensor], 1)    # shape = (z_batch_size, 256)\n",
    "print(z.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
