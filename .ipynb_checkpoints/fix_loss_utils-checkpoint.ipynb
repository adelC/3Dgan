{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A file to fix the ecal_ang() and ecal_sum() lambda loss term functions\n",
    "## (1) remove keras and (2) allow for different sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras as K\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import h5py\n",
    "from numpy import asarray\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum_5:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SIMPLE DEBUGGING VARIABLES\n",
    "#daxis=(1,1)\n",
    "#c = tf.constant([[1.0, 2.0, 4.0], [3.0, 4.0, 5.0]])\n",
    "#c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDataAngle(datafile, imgs3dscale =1, imgs3dpower=1, e_pscale = 100, angscale=1, angtype='theta', thresh=1e-4):\n",
    "    print ('Loading Data from .....', datafile)\n",
    "    f = h5py.File(datafile,'r')                    # load data into f variable\n",
    "    ang = np.array(f.get(angtype))                 # ang is an array of angle data from f, one value is concatenated onto the latent vector\n",
    "    imgs3d = np.array(f.get('ECAL'))* imgs3dscale    # imgs3d is a 3d array, cut from the cylinder that the calorimeter produces -has 25 layers along z-axis\n",
    "    e_p = np.array(f.get('energy'))/e_pscale       # e_p is an array of scaled energy data from f, one value is concatenated onto the latent vector\n",
    "    imgs3d[imgs3d < thresh] = 0        # when imgs3d values are less than the threshold, they are reset to 0\n",
    "    \n",
    "    # set imgs3d, e_p, and ang as float 32 datatypes\n",
    "    imgs3d = imgs3d.astype(np.float32)\n",
    "    e_p = e_p.astype(np.float32)\n",
    "    ang = ang.astype(np.float32)\n",
    "    \n",
    "    imgs3d = np.expand_dims(imgs3d, axis=-1)         # insert a new axis at the beginning for imgs3d\n",
    "    \n",
    "    # sum along axis\n",
    "    ecal = np.sum(imgs3d, axis=(1, 2, 3))    # summed imgs3d data, used for training the discriminator\n",
    "     \n",
    "    # imgs3d ^ imgs3dpower\n",
    "    if imgs3dpower !=1.:\n",
    "        imgs3d = np.power(imgs3d, imgs3dpower)\n",
    "            \n",
    "    # imgs3d=ecal data; e_p=energy data; ecal=summed imgs3d (used to train the discriminator); ang=angle data\n",
    "    return imgs3d, e_p, ang, ecal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data from ..... Ele_VarAngleMeas_100_200_005.h5\n"
     ]
    }
   ],
   "source": [
    "# load and process the image\n",
    "imgs3d, e_p, ang, ecal = GetDataAngle('Ele_VarAngleMeas_100_200_005.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(51), Dimension(51), Dimension(25), Dimension(1)])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = imgs3d[0, :, :, :]\n",
    "#inv_image = Lambda(tf.pow, arguments={'a':1./power})(image) #get back original image\n",
    "power = 1.   # from anglearch discriminator\n",
    "inv_image = tf.math.pow(image, 1./power)\n",
    "inv_image.shape\n",
    "#print(image.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 'channels_last'    # for cpu\n",
    "if channel =='channels_last':\n",
    "    daxis=(1,2,3)\n",
    "    dshape=(51, 51, 25,1)\n",
    "else:\n",
    "    daxis=(2,3,4)\n",
    "    dshape=(1, 51, 51, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original ecal_sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summming cell energies\n",
    "def ecal_sum(image, power):\n",
    "    image = K.pow(image, 1./power)\n",
    "    sum = K.sum(image, axis=daxis)\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New ecal_sum() \n",
    "#### do i need to multiply by a value for smaller images??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summming cell energies\n",
    "def ecal_sum(image, daxis):\n",
    "    # sum the values along the daxis\n",
    "    sum = tf.math.reduce_sum(image, daxis)   \n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51,)\n",
      "[0.0000000e+00 1.8364752e-02 4.3075765e-04 0.0000000e+00 4.4391233e-02\n",
      " 9.3818288e-03 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.2995591e-02\n",
      " 2.2352263e-02 6.0335203e-04 4.8684012e-02 3.6378667e-02 5.6574674e-04\n",
      " 9.2993975e-02 2.4772234e-01 1.7715459e-01 1.6063562e-01 6.1734945e-01\n",
      " 5.9460270e-01 1.3094927e+00 2.4457004e+00 7.1400309e+00 2.9429686e+01\n",
      " 7.5099014e+01 2.2078119e+01 5.3848667e+00 2.2938156e+00 1.1262442e+00\n",
      " 7.0753396e-01 2.8769591e-01 4.8109412e-01 2.1767995e-01 1.0848482e-01\n",
      " 1.7678861e-01 3.0452311e-02 3.2676924e-02 5.7645768e-02 2.9066708e-02\n",
      " 3.0731838e-02 4.4610746e-02 7.3493175e-02 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 6.5816217e-03 8.6895879e-03 5.1934272e-02 4.3599587e-02\n",
      " 3.2618808e-04]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "#print(tf.Session().run(new_ecal_sum(c, 2)))\n",
    "print(ecal_sum(inv_image, daxis).shape)\n",
    "print(tf.Session().run(ecal_sum(inv_image, daxis)))\n",
    "print(ecal_sum(inv_image, daxis).shape)\n",
    "print(tf.Session().run(ecal_sum(inv_image, daxis)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original ecal_angle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating angle from image\n",
    "def ecal_angle(image, power):\n",
    "    image = K.squeeze(image, axis=daxis)# squeeze along channel axis\n",
    "    \n",
    "    # size of ecal\n",
    "    x_shape= K.int_shape(image)[1]\n",
    "    y_shape= K.int_shape(image)[2]\n",
    "    z_shape= K.int_shape(image)[3]\n",
    "    sumtot = K.sum(image, axis=(1,2,3))# sum of events\n",
    "    \n",
    "    # get 1. where event sum is 0 and 0 elsewhere\n",
    "    amask = K.tf.where(tf.math.equal(sumtot, 0.0), K.ones_like(sumtot) , K.zeros_like(sumtot))\n",
    "    masked_events = K.sum(amask) # counting zero sum events\n",
    "    \n",
    "    # ref denotes barycenter as that is our reference point\n",
    "    x_ref = K.sum(K.sum(image, axis=(2,3)) * (K.cast(K.expand_dims(K.arange(x_shape), 0), dtype='float32') + 0.5) , axis=1)# sum for x position * x index\n",
    "    y_ref = K.sum(K.sum(image, axis=(1,3)) * (K.cast(K.expand_dims(K.arange(y_shape), 0), dtype='float32') + 0.5), axis=1)\n",
    "    z_ref = K.sum(K.sum(image, axis=(1,2)) * (K.cast(K.expand_dims(K.arange(z_shape), 0), dtype='float32') + 0.5), axis=1)\n",
    "    x_ref = K.tf.where(K.equal(sumtot, 0.0), K.ones_like(x_ref) , x_ref/sumtot)# return max position if sumtot=0 and divide by sumtot otherwise\n",
    "    y_ref = K.tf.where(K.equal(sumtot, 0.0), K.ones_like(y_ref) , y_ref/sumtot)\n",
    "    z_ref = K.tf.where(K.equal(sumtot, 0.0), K.ones_like(z_ref), z_ref/sumtot)\n",
    "    \n",
    "    # reshape    \n",
    "    x_ref = K.expand_dims(x_ref, 1)\n",
    "    y_ref = K.expand_dims(y_ref, 1)\n",
    "    z_ref = K.expand_dims(z_ref, 1)\n",
    "\n",
    "    sumz = K.sum(image, axis =(1,2)) # sum for x,y planes going along z\n",
    "\n",
    "    # Get 0 where sum along z is 0 and 1 elsewhere\n",
    "    zmask = K.tf.where(K.equal(sumz, 0.0), K.zeros_like(sumz) , K.ones_like(sumz))\n",
    "        \n",
    "    x = K.expand_dims(K.arange(x_shape), 0) # x indexes\n",
    "    x = K.cast(K.expand_dims(x, 2), dtype='float32') + 0.5\n",
    "    y = K.expand_dims(K.arange(y_shape), 0)# y indexes\n",
    "    y = K.cast(K.expand_dims(y, 2), dtype='float32') + 0.5\n",
    "  \n",
    "    # barycenter for each z position\n",
    "    x_mid = K.sum(K.sum(image, axis=2) * x, axis=1)\n",
    "    y_mid = K.sum(K.sum(image, axis=1) * y, axis=1)\n",
    "    x_mid = K.tf.where(K.equal(sumz, 0.0), K.zeros_like(sumz), x_mid/sumz) # if sum != 0 then divide by sum\n",
    "    y_mid = K.tf.where(K.equal(sumz, 0.0), K.zeros_like(sumz), y_mid/sumz) # if sum != 0 then divide by sum\n",
    "\n",
    "    # Angle Calculations\n",
    "    z = (K.cast(K.arange(z_shape), dtype='float32') + 0.5)  * K.ones_like(z_ref) # Make an array of z indexes for all events\n",
    "    zproj = K.sqrt(K.maximum((x_mid-x_ref)**2.0 + (z - z_ref)**2.0, K.epsilon()))# projection from z axis with stability check\n",
    "    m = K.tf.where(K.equal(zproj, 0.0), K.zeros_like(zproj), (y_mid-y_ref)/zproj)# to avoid divide by zero for zproj =0\n",
    "    m = K.tf.where(K.tf.less(z, z_ref),  -1 * m, m)# sign inversion\n",
    "    ang = (math.pi/2.0) - tf.atan(m)# angle correction\n",
    "    zmask = K.tf.where(K.equal(zproj, 0.0), K.zeros_like(zproj) , zmask)\n",
    "    ang = ang * zmask # place zero where zsum is zero\n",
    "    \n",
    "    ang = ang * z  # weighted by position\n",
    "    sumz_tot = z * zmask # removing indexes with 0 energies or angles\n",
    "\n",
    "    #zunmasked = K.sum(zmask, axis=1) # used for simple mean \n",
    "    #ang = K.sum(ang, axis=1)/zunmasked # Mean does not include positions where zsum=0\n",
    "\n",
    "    ang = K.sum(ang, axis=1)/K.sum(sumz_tot, axis=1) # sum ( measured * weights)/sum(weights)\n",
    "    ang = K.tf.where(K.equal(amask, 0.), ang, 100. * K.ones_like(ang)) # Place 100 for measured angle where no energy is deposited in events\n",
    "    \n",
    "    ang = K.expand_dims(ang, 1)\n",
    "    return ang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new ecal_angle() -- accounting for different sizes -- in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating angle from image\n",
    "def ecal_angle(image, size, channel_included=False, inverted=True):#, daxis):\n",
    "    # pgan image shape will be either (z=shape/2, x=shape, y=shape) or (channel=1, z=shape/2, x=shape, y=shape)\n",
    "    if channel_included:    \n",
    "        image = tf.squeeze(image) # get rid of channel dimension\n",
    "        print('removed channels dimension! ', image.shape)\n",
    "        \n",
    "    # switch dimensions ordering from pgan (z,x,y) back to anglegan (x,y,z)\n",
    "    if size != 51:\n",
    "        image = np.moveaxis(image, 0, -1)   # move z back\n",
    "    xdim, ydim, zdim = 0, 1, 2  \n",
    "    print('xdim, ydim, zdim: ', xdim, ydim, zdim)\n",
    "    \n",
    "    if not inverted:\n",
    "        # pre-process the image (the og image is inverted in getdataangle())\n",
    "        image = tf.pow(image, 1./power)   \n",
    "     \n",
    "    # size of ecal\n",
    "    x_shape, y_shape, z_shape = size, size, int(size/2)\n",
    "    print('x_shape, y_shape, z_shape: ', x_shape, y_shape, z_shape)\n",
    "    sumtot = tf.math.reduce_sum(image, (0,1,2))# sum of events\n",
    "    print('sumtot: ',tf.Session().run(sumtot))\n",
    "\n",
    "    # get 1. where event sum is 0 and 0 elsewhere\n",
    "    amask = tf.where(tf.math.equal(sumtot, 0.0), tf.ones_like(sumtot) , tf.zeros_like(sumtot))\n",
    "    print('amask: ',amask)#tf.Session().run(amask))\n",
    "    masked_events = tf.math.reduce_sum(amask) # counting zero sum events\n",
    "    \n",
    "    # ref denotes barycenter as that is our reference point\n",
    "    x_ref = tf.math.reduce_sum(tf.math.reduce_sum(image, (ydim,zdim)) * (tf.cast(tf.expand_dims(tf.range(x_shape), 0), dtype='float32') + 0.5), xdim)# sum for x position * x index\n",
    "    y_ref = tf.math.reduce_sum(tf.math.reduce_sum(image, (xdim,zdim)) * (tf.cast(tf.expand_dims(tf.range(y_shape), 0), dtype='float32') + 0.5), xdim)\n",
    "    z_ref = tf.math.reduce_sum(tf.math.reduce_sum(image, (xdim,ydim)) * (tf.cast(tf.expand_dims(tf.range(z_shape), 0), dtype='float32') + 0.5), xdim)\n",
    "    # return max position if sumtot=0 and divide by sumtot otherwise\n",
    "    x_ref = tf.where(tf.math.equal(sumtot, 0.0), tf.ones_like(x_ref), x_ref/sumtot)\n",
    "    y_ref = tf.where(tf.math.equal(sumtot, 0.0), tf.ones_like(y_ref), y_ref/sumtot)\n",
    "    z_ref = tf.where(tf.math.equal(sumtot, 0.0), tf.ones_like(z_ref), z_ref/sumtot)\n",
    "    \n",
    "    # reshape - put in value at the beginning    \n",
    "    x_ref = tf.expand_dims(x_ref, 0)\n",
    "    y_ref = tf.expand_dims(y_ref, 0)\n",
    "    z_ref = tf.expand_dims(z_ref, 0)\n",
    "\n",
    "    sumz = tf.math.reduce_sum(image, axis =(xdim,ydim)) # sum for x,y planes going along z\n",
    "\n",
    "    # Get 0 where sum along z is 0 and 1 elsewhere\n",
    "    zmask = tf.where(tf.math.equal(sumz, 0.0), tf.zeros_like(sumz) , tf.ones_like(sumz))\n",
    "        \n",
    "    x = tf.expand_dims(tf.range(x_shape), 0) # x indexes\n",
    "    x = tf.cast(tf.expand_dims(x, 1), dtype='float32') + 0.5\n",
    "    y = tf.expand_dims(tf.range(y_shape), 0)# y indexes\n",
    "    y = tf.cast(tf.expand_dims(y, 1), dtype='float32') + 0.5\n",
    "  \n",
    "    # barycenter for each z position\n",
    "    x_mid = tf.math.reduce_sum(tf.math.reduce_sum(image, axis=2) * x, axis=1)\n",
    "    y_mid = tf.math.reduce_sum(tf.math.reduce_sum(image, axis=1) * y, axis=1)\n",
    "    x_mid = tf.where(tf.math.equal(sumz, 0.0), tf.zeros_like(sumz), x_mid/sumz) # if sum != 0 then divide by sum\n",
    "    y_mid = tf.where(tf.math.equal(sumz, 0.0), tf.zeros_like(sumz), y_mid/sumz) # if sum != 0 then divide by sum\n",
    "\n",
    "    # Angle Calculations\n",
    "    z = (tf.cast(tf.range(z_shape), dtype='float32') + 0.5)  * tf.ones_like(z_ref) # Make an array of z indexes for all events\n",
    "    epsilon = 0.0000007  # replaces k.epsilon(), used as fluff value to prevent /0 errors\n",
    "    zproj = tf.math.sqrt(tf.math.maximum((x_mid-x_ref)**2.0 + (z - z_ref)**2.0, epsilon))# projection from z axis with stability check\n",
    "    m = tf.where(tf.math.equal(zproj, 0.0), tf.zeros_like(zproj), (y_mid-y_ref)/zproj)# to avoid divide by zero for zproj =0\n",
    "    m = tf.where(tf.math.less(z, z_ref),  -1 * m, m)   # sign inversion\n",
    "    ang = (math.pi/2.0) - tf.atan(m)   # angle correction\n",
    "    zmask = tf.where(tf.math.equal(zproj, 0.0), tf.zeros_like(zproj), zmask)\n",
    "    ang = ang * zmask # place zero where zsum is zero\n",
    "    \n",
    "    ang = ang * z  # weighted by position\n",
    "    sumz_tot = z * zmask # removing indexes with 0 energies or angles\n",
    "\n",
    "    #zunmasked = tf.math.reduce_sum(zmask, axis=1) # used for simple mean \n",
    "    #ang = tf.math.reduce_sum(ang, axis=1)/zunmasked # Mean does not include positions where zsum=0\n",
    "\n",
    "    ang = tf.math.reduce_sum(ang, axis=0)/tf.math.reduce_sum(sumz_tot, axis=0) # sum ( measured * weights)/sum(weights)\n",
    "    ang = tf.where(tf.math.equal(amask, 0.), ang, 100. * tf.ones_like(ang)) # Place 100 for measured angle where no energy is deposited in events\n",
    "    \n",
    "    ang = tf.expand_dims(ang, 0)\n",
    "    return ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed channels dimension!  (51, 51, 25)\n",
      "xdim, ydim, zdim:  0 1 2\n",
      "x_shape, y_shape, z_shape:  51 51 25\n",
      "sumtot:  150.78069\n",
      "amask:  Tensor(\"Select_52:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 25 and 51 for 'mul_54' (op: 'Mul') with input shapes: [51,25], [1,1,51].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1606\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1607\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1608\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 25 and 51 for 'mul_54' (op: 'Mul') with input shapes: [51,25], [1,1,51].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-6e239de5c03e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#daxis = (0,1,2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mecal_angle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minv_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m51\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel_included\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, daxis)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-135-e7df6a7bfc30>\u001b[0m in \u001b[0;36mecal_angle\u001b[1;34m(image, size, channel_included, inverted)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;31m# barycenter for each z position\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mx_mid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0my_mid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mx_mid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msumz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msumz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_mid\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msumz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# if sum != 0 then divide by sum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0my_mid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msumz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msumz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_mid\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msumz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# if sum != 0 then divide by sum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    900\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1204\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1206\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1207\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Case: Dense * Sparse.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6698\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6699\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 6700\u001b[1;33m         \"Mul\", x=x, y=y, name=name)\n\u001b[0m\u001b[0;32m   6701\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6702\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    792\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[0;32m    793\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m       \u001b[1;31m# Conditionally invoke tfdbg v2's op callback(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3355\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input #%d is not a tensor: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3356\u001b[0m     return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n\u001b[1;32m-> 3357\u001b[1;33m                                     attrs, op_def, compute_device)\n\u001b[0m\u001b[0;32m   3358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3359\u001b[0m   def _create_op_internal(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3424\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3425\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3426\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3427\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3428\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1768\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1769\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1770\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1771\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1608\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1609\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1610\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1612\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 25 and 51 for 'mul_54' (op: 'Mul') with input shapes: [51,25], [1,1,51]."
     ]
    }
   ],
   "source": [
    "#daxis = (0,1,2)\n",
    "ecal_angle(inv_image, 51, channel_included=True)#, daxis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new ecal_angle() -- converts to og size -- in progress, currently only works with 64-->OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in the pgan generated 3d images of size [nmbr_of_images, 32, 64, 64] and resizes them to the desired [nmbr_of_images, 51, 51, 25] OG shape\n",
    "# include channels changes??? -- may need to debug if channels value is included in pgan_imgs\n",
    "def restore_pics(pgan_imgs3d):\n",
    "    # matrix dimensions: [nmbr_of_images, 32, 64, 64] --> [nmbr_of_images, 51, 51, 25]\n",
    "    og_dim_imgs3d = np.moveaxis(pgan_imgs3d, 1, -1)   # move z: [nmbr_of_images, 64, 64, 32]\n",
    "    og_dim_imgs3d = og_dim_imgs3d[:, 7:58, 7:58, 4:29]   # crop centrally (corresponding to resize()) to og_dimensions 51x51x25\n",
    "    return og_dim_imgs3d\n",
    "\n",
    "def restore_pic(image, size):\n",
    "    # matrix dimensions: [32, 64, 64] --> [51, 51, 25]\n",
    "    restored_image = np.moveaxis(image, 0, -1)   # move z back: [x,y,z]\n",
    "    if size == 64:\n",
    "        restored_image = restored_image[7:58, 7:58, 4:29]   # crop centrally (corresponding to resize()) to og_dimensions 51x51x25\n",
    "    else: # size = 8, 16, 32\n",
    "                # resize XY-plane to (size x size)\n",
    "                xy_restored_image = np.zeros((51,51,size/2))   # create an empty 3d_image to store changes\n",
    "                for z_index in np.arange(inte(size/2)):    # index through the 25 calorimeter layers of the z-axis\n",
    "                    img2d = restored_image[:, :, z_index]   # grab a 2d image from the xy plane\n",
    "                    resized_img2d = cv2.resize(img2d, dsize=(51,51), interpolation=cv2.INTER_NEAREST)\n",
    "                    xy_restored_image[:, :, z_index] = resized_img2d   # save our resized_img2d in the img3d corresponding to the calorimeter layer\n",
    "\n",
    "                # resize YZ-plane to (size x size/2)\n",
    "                restored_image = np.zeros((size, size, int(size/2)))   # create an empty 3d_image to store changes            # resize YZ-plane to (size,size)=square or (size,size/2)=rectangle\n",
    "                for x_index in np.arange(size):    # index through the x-axis\n",
    "                    img2d = xy_restored_image[x_index, :, :]\n",
    "                    resized_img2d = cv2.resize(img2d, dsize=(int(size/2), size), interpolation=cv2.INTER_NEAREST)\n",
    "                    restored_image[x_index, :, :] = resized_img2d   # save our resized_img2d in the img3d corresponding to the x layer\n",
    "    return restored_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating angle from image\n",
    "def ecal_angle(image, size, channel_included=False, inverted=True):#, daxis):\n",
    "    # pgan image shape will be either (z=shape/2, x=shape, y=shape) or (channel=1, z=shape/2, x=shape, y=shape)\n",
    "    if channel_included:    \n",
    "        image = tf.squeeze(image) # get rid of channel dimension\n",
    "    \n",
    "    # convert pgan image [32,64,64] to OG [51,51,25] size\n",
    "    image = restore_pic(image, size)\n",
    "    xdim, ydim, zdim = 0, 1, 2  \n",
    "    \n",
    "    if not inverted:\n",
    "        # pre-process the image (the og image is inverted in getdataangle())\n",
    "        image = tf.pow(image, 1./power)   \n",
    "    \n",
    "    # size of ecal\n",
    "    x_shape, y_shape, z_shape = 51, 51, 25\n",
    "    sumtot = tf.math.reduce_sum(image, (xdim,ydim,zdim))# sum of events\n",
    "\n",
    "    # get 1. where event sum is 0 and 0 elsewhere\n",
    "    amask = tf.where(tf.math.equal(sumtot, 0.0), tf.ones_like(sumtot) , tf.zeros_like(sumtot))\n",
    "    masked_events = tf.math.reduce_sum(amask) # counting zero sum events\n",
    "    \n",
    "    # ref denotes barycenter as that is our reference point\n",
    "    x_ref = tf.math.reduce_sum(tf.math.reduce_sum(image, (ydim,zdim)) * (tf.cast(tf.expand_dims(tf.range(x_shape), 0), dtype='float32') + 0.5), xdim)# sum for x position * x index\n",
    "    y_ref = tf.math.reduce_sum(tf.math.reduce_sum(image, (xdim,zdim)) * (tf.cast(tf.expand_dims(tf.range(y_shape), 0), dtype='float32') + 0.5), xdim)\n",
    "    z_ref = tf.math.reduce_sum(tf.math.reduce_sum(image, (xdim,ydim)) * (tf.cast(tf.expand_dims(tf.range(z_shape), 0), dtype='float32') + 0.5), xdim)\n",
    "    # return max position if sumtot=0 and divide by sumtot otherwise\n",
    "    x_ref = tf.where(tf.math.equal(sumtot, 0.0), tf.ones_like(x_ref), x_ref/sumtot)\n",
    "    y_ref = tf.where(tf.math.equal(sumtot, 0.0), tf.ones_like(y_ref), y_ref/sumtot)\n",
    "    z_ref = tf.where(tf.math.equal(sumtot, 0.0), tf.ones_like(z_ref), z_ref/sumtot)\n",
    "    \n",
    "    # reshape - put in value at the beginning    \n",
    "    x_ref = tf.expand_dims(x_ref, 0)\n",
    "    y_ref = tf.expand_dims(y_ref, 0)\n",
    "    z_ref = tf.expand_dims(z_ref, 0)\n",
    "\n",
    "    sumz = tf.math.reduce_sum(image, axis =(xdim,ydim)) # sum for x,y planes going along z\n",
    "\n",
    "    # Get 0 where sum along z is 0 and 1 elsewhere\n",
    "    zmask = tf.where(tf.math.equal(sumz, 0.0), tf.zeros_like(sumz) , tf.ones_like(sumz))\n",
    "        \n",
    "    x = tf.expand_dims(tf.range(x_shape), 0) # x indexes\n",
    "    x = tf.cast(tf.expand_dims(x, 1), dtype='float32') + 0.5\n",
    "    y = tf.expand_dims(tf.range(y_shape), 0)# y indexes\n",
    "    y = tf.cast(tf.expand_dims(y, 1), dtype='float32') + 0.5\n",
    "  \n",
    "    # barycenter for each z position\n",
    "    x_mid = tf.math.reduce_sum(tf.math.reduce_sum(image, axis=1) * x, axis=0)\n",
    "    y_mid = tf.math.reduce_sum(tf.math.reduce_sum(image, axis=0) * y, axis=0)\n",
    "    x_mid = tf.where(tf.math.equal(sumz, 0.0), tf.zeros_like(sumz), x_mid/sumz) # if sum != 0 then divide by sum\n",
    "    y_mid = tf.where(tf.math.equal(sumz, 0.0), tf.zeros_like(sumz), y_mid/sumz) # if sum != 0 then divide by sum\n",
    "\n",
    "    # Angle Calculations\n",
    "    z = (tf.cast(tf.range(z_shape), dtype='float32') + 0.5)  * tf.ones_like(z_ref) # Make an array of z indexes for all events\n",
    "    epsilon = 0.0000007  # replaces k.epsilon(), used as fluff value to prevent /0 errors\n",
    "    zproj = tf.math.sqrt(tf.math.maximum((x_mid-x_ref)**2.0 + (z - z_ref)**2.0, epsilon))# projection from z axis with stability check\n",
    "    m = tf.where(tf.math.equal(zproj, 0.0), tf.zeros_like(zproj), (y_mid-y_ref)/zproj)# to avoid divide by zero for zproj =0\n",
    "    m = tf.where(tf.math.less(z, z_ref),  -1 * m, m)   # sign inversion\n",
    "    ang = (math.pi/2.0) - tf.atan(m)   # angle correction\n",
    "    zmask = tf.where(tf.math.equal(zproj, 0.0), tf.zeros_like(zproj), zmask)\n",
    "    ang = ang * zmask # place zero where zsum is zero\n",
    "    \n",
    "    ang = ang * z  # weighted by position\n",
    "    sumz_tot = z * zmask # removing indexes with 0 energies or angles\n",
    "\n",
    "    #zunmasked = tf.math.reduce_sum(zmask, axis=1) # used for simple mean \n",
    "    #ang = tf.math.reduce_sum(ang, axis=1)/zunmasked # Mean does not include positions where zsum=0\n",
    "\n",
    "    ang = tf.math.reduce_sum(ang, axis=0)/tf.math.reduce_sum(sumz_tot, axis=0) # sum ( measured * weights)/sum(weights)\n",
    "    ang = tf.where(tf.math.equal(amask, 0.), ang, 100. * tf.ones_like(ang)) # Place 100 for measured angle where no energy is deposited in events\n",
    "    \n",
    "    ang = tf.expand_dims(ang, 0)\n",
    "    return ang"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
