!_TAG_FILE_FORMAT	2	/extended format; --format=1 will not append ;" to lines/
!_TAG_FILE_SORTED	1	/0=unsorted, 1=sorted, 2=foldcase/
!_TAG_PROGRAM_AUTHOR	Darren Hiebert	/dhiebert@users.sourceforge.net/
!_TAG_PROGRAM_NAME	Exuberant Ctags	//
!_TAG_PROGRAM_URL	http://ctags.sourceforge.net	/official site/
!_TAG_PROGRAM_VERSION	5.8	//
Conv3D	AngleGAN/discriminator.py	/^from keras.layers.convolutional import (UpSampling3D, Conv3D, ZeroPadding3D,$/;"	i
Conv3D	AngleGAN/generator.py	/^from keras.layers.convolutional import (UpSampling3D, Conv3D, ZeroPadding3D,$/;"	i
Dense	AngleGAN/discriminator.py	/^from keras.layers import (Input, Dense, Reshape, Flatten, Lambda, merge,$/;"	i
Dense	AngleGAN/generator.py	/^from keras.layers import (Input, Dense, Reshape, Flatten, Lambda, merge,$/;"	i
Flatten	AngleGAN/discriminator.py	/^from keras.layers import (Input, Dense, Reshape, Flatten, Lambda, merge,$/;"	i
Flatten	AngleGAN/generator.py	/^from keras.layers import (Input, Dense, Reshape, Flatten, Lambda, merge,$/;"	i
HDF5File	AngleGAN/discriminator.py	/^from h5py import File as HDF5File$/;"	i
HDF5File	AngleGAN/generator.py	/^from h5py import File as HDF5File$/;"	i
Input	AngleGAN/discriminator.py	/^from keras.layers import (Input, Dense, Reshape, Flatten, Lambda, merge,$/;"	i
Input	AngleGAN/generator.py	/^from keras.layers import (Input, Dense, Reshape, Flatten, Lambda, merge,$/;"	i
K	AngleGAN/discriminator.py	/^import keras.backend as K$/;"	i
K	AngleGAN/generator.py	/^import keras.backend as K$/;"	i
Lambda	AngleGAN/discriminator.py	/^from keras.layers import (Input, Dense, Reshape, Flatten, Lambda, merge,$/;"	i
Lambda	AngleGAN/generator.py	/^from keras.layers import (Input, Dense, Reshape, Flatten, Lambda, merge,$/;"	i
LeakyReLU	AngleGAN/discriminator.py	/^from keras.layers.advanced_activations import LeakyReLU$/;"	i
LeakyReLU	AngleGAN/generator.py	/^from keras.layers.advanced_activations import LeakyReLU$/;"	i
Model	AngleGAN/discriminator.py	/^from keras.models import Model, Sequential$/;"	i
Model	AngleGAN/generator.py	/^from keras.models import Model, Sequential$/;"	i
Reshape	AngleGAN/discriminator.py	/^from keras.layers import (Input, Dense, Reshape, Flatten, Lambda, merge,$/;"	i
Reshape	AngleGAN/generator.py	/^from keras.layers import (Input, Dense, Reshape, Flatten, Lambda, merge,$/;"	i
Sequential	AngleGAN/discriminator.py	/^from keras.models import Model, Sequential$/;"	i
Sequential	AngleGAN/generator.py	/^from keras.models import Model, Sequential$/;"	i
Tensor	AngleGAN/discriminator.py	/^from tensorflow import py_func, float32, Tensor$/;"	i
Tensor	AngleGAN/generator.py	/^from tensorflow import py_func, float32, Tensor$/;"	i
UpSampling3D	AngleGAN/discriminator.py	/^from keras.layers.convolutional import (UpSampling3D, Conv3D, ZeroPadding3D,$/;"	i
UpSampling3D	AngleGAN/generator.py	/^from keras.layers.convolutional import (UpSampling3D, Conv3D, ZeroPadding3D,$/;"	i
ZeroPadding3D	AngleGAN/discriminator.py	/^from keras.layers.convolutional import (UpSampling3D, Conv3D, ZeroPadding3D,$/;"	i
ZeroPadding3D	AngleGAN/generator.py	/^from keras.layers.convolutional import (UpSampling3D, Conv3D, ZeroPadding3D,$/;"	i
act	ops.py	/^def act(x, activation, param=None):$/;"	f
apply_bias	ops.py	/^def apply_bias(x, lrmul=1):$/;"	f
apply_noise	ops.py	/^def apply_noise(x):$/;"	f
avg_pool3d	ops.py	/^def avg_pool3d(x, factor=2, gain=1):$/;"	f
avg_unpool3d	ops.py	/^def avg_unpool3d(x, factor=2, gain=1):$/;"	f
base_dim	pgan/discriminator.py	/^    base_dim = 1024$/;"	v
base_dim	pgan/generator.py	/^    base_dim = 1024$/;"	v
base_dim	test_network.py	/^    base_dim = 512$/;"	v
base_shape	pgan/discriminator.py	/^    base_shape = [1, 1, 4, 4]$/;"	v
base_shape	pgan/generator.py	/^    base_shape = [1, 1, 4, 4]$/;"	v
base_shape	test_network.py	/^    base_shape = [1, 1, 4, 4]$/;"	v
bce	loss.py	/^from networks.pgan.loss_utils import bce, mae, mape  # loss functions used for loss_fn='anglegan'$/;"	i
bce	pgan/loss_utils.py	/^def bce(output, target, from_logits=False):$/;"	f
be	loss.py	/^from networks.pgan.loss_utils import ecal_sum, ecal_angle # physics functions used for training the discriminator (should be in conditional lambda layer)$/;"	i
calculate_gain	ops.py	/^def calculate_gain(activation, param=None):$/;"	f
conditional	loss.py	/^from networks.pgan.loss_utils import ecal_sum, ecal_angle # physics functions used for training the discriminator (should be in conditional lambda layer)$/;"	i
conv3d	ops.py	/^def conv3d(x, fmaps, kernel, activation, param=None, lrmul=1):$/;"	f
conv3d_depthwise	ops.py	/^def conv3d_depthwise(x, f, strides, padding):$/;"	f
count	AngleGAN/discriminator.py	/^from GANutils import ecal_sum, count, ecal_angle$/;"	i
count	AngleGAN/generator.py	/^from GANutils import ecal_sum, count, ecal_angle$/;"	i
count_parameters	test_network.py	/^from utils import count_parameters$/;"	i
daxis	AngleGAN/discriminator.py	/^    daxis=(1,2,3)$/;"	v
daxis	AngleGAN/discriminator.py	/^    daxis=(2,3,4)$/;"	v
daxis	AngleGAN/generator.py	/^    daxis=(1,2,3)$/;"	v
daxis	AngleGAN/generator.py	/^    daxis=(2,3,4)$/;"	v
dense	ops.py	/^def dense(x, fmaps, activation, lrmul=1, param=None):$/;"	f
discriminator	AngleGAN/discriminator.py	/^def discriminator(power=1.0):$/;"	f
discriminator	loss.py	/^from networks.pgan.loss_utils import ecal_sum, ecal_angle # physics functions used for training the discriminator (should be in conditional lambda layer)$/;"	i
discriminator	pgan/discriminator.py	/^def discriminator(x, alpha, phase, num_phases, base_shape, base_dim, latent_dim, activation, param=None, is_reuse=False, size='medium', conditioning=None):$/;"	f
discriminator_block	pgan/discriminator.py	/^def discriminator_block(x, filters_in, filters_out, activation, param=None):$/;"	f
discriminator_out	pgan/discriminator.py	/^def discriminator_out(x, base_dim, latent_dim, filters_out, activation, param):$/;"	f
downscale3d	ops.py	/^def downscale3d(x, factor=2):$/;"	f
ecal_angle	AngleGAN/discriminator.py	/^from GANutils import ecal_sum, count, ecal_angle$/;"	i
ecal_angle	AngleGAN/generator.py	/^from GANutils import ecal_sum, count, ecal_angle$/;"	i
ecal_angle	loss.py	/^from networks.pgan.loss_utils import ecal_sum, ecal_angle # physics functions used for training the discriminator (should be in conditional lambda layer)$/;"	i
ecal_angle	pgan/discriminator.py	/^from networks.pgan.loss_utils import ecal_sum, ecal_angle$/;"	i
ecal_angle	pgan/loss_utils.py	/^def ecal_angle(images, size, power=1.0):$/;"	f
ecal_sum	AngleGAN/discriminator.py	/^from GANutils import ecal_sum, count, ecal_angle$/;"	i
ecal_sum	AngleGAN/generator.py	/^from GANutils import ecal_sum, count, ecal_angle$/;"	i
ecal_sum	loss.py	/^from networks.pgan.loss_utils import ecal_sum, ecal_angle # physics functions used for training the discriminator (should be in conditional lambda layer)$/;"	i
ecal_sum	pgan/discriminator.py	/^from networks.pgan.loss_utils import ecal_sum, ecal_angle$/;"	i
ecal_sum	pgan/loss_utils.py	/^def ecal_sum(images, size, power=1.0):   $/;"	f
end	test_network.py	/^            end = time.time()$/;"	v
final_shape	test_network.py	/^    final_shape = [1, 128, 512, 512]$/;"	v
float32	AngleGAN/discriminator.py	/^from tensorflow import py_func, float32, Tensor$/;"	i
float32	AngleGAN/generator.py	/^from tensorflow import py_func, float32, Tensor$/;"	i
for	loss.py	/^from networks.pgan.loss_utils import bce, mae, mape  # loss functions used for loss_fn='anglegan'$/;"	i
for	loss.py	/^from networks.pgan.loss_utils import ecal_sum, ecal_angle # physics functions used for training the discriminator (should be in conditional lambda layer)$/;"	i
forward_discriminator	loss.py	/^def forward_discriminator(generator,$/;"	f
forward_generator	loss.py	/^def forward_generator(generator,$/;"	f
forward_simultaneous	loss.py	/^def forward_simultaneous(generator,$/;"	f
from_rgb	ops.py	/^def from_rgb(x, filters_out, activation, param=None):$/;"	f
func	ops.py	/^        def func(x):$/;"	f	function:downscale3d
func	ops.py	/^        def func(x):$/;"	f	function:leaky_relu
func	ops.py	/^        def func(x):$/;"	f	function:upscale3d
functions	loss.py	/^from networks.pgan.loss_utils import bce, mae, mape  # loss functions used for loss_fn='anglegan'$/;"	i
functions	loss.py	/^from networks.pgan.loss_utils import ecal_sum, ecal_angle # physics functions used for training the discriminator (should be in conditional lambda layer)$/;"	i
generator	AngleGAN/generator.py	/^def generator(latent_size=254, return_intermediate=False):$/;"	f
generator	pgan/generator.py	/^def generator(x, alpha, phase, num_phases, base_dim, base_shape, activation, param=None, size='medium', is_reuse=False, conditioning=None):$/;"	f
generator_block	pgan/generator.py	/^def generator_block(x, filters_out, activation, param=None):$/;"	f
generator_in	pgan/generator.py	/^def generator_in(x, filters, shape, activation, param=None):$/;"	f
get_weight	ops.py	/^def get_weight(shape, activation, lrmul=1, use_eq_lr=True, use_spectral_norm=False, param=None):$/;"	f
grad	ops.py	/^            def grad(dy):$/;"	f	function:downscale3d.func
grad	ops.py	/^            def grad(dy):$/;"	f	function:leaky_relu.func
grad	ops.py	/^            def grad(dy):$/;"	f	function:upscale3d.func
group_conv3d	ops.py	/^def group_conv3d(x, filter, groups):$/;"	f
h5py	AngleGAN/discriminator.py	/^import h5py$/;"	i
h5py	AngleGAN/generator.py	/^import h5py$/;"	i
importlib	test_network.py	/^import importlib$/;"	i
in	loss.py	/^from networks.pgan.loss_utils import ecal_sum, ecal_angle # physics functions used for training the discriminator (should be in conditional lambda layer)$/;"	i
init_op	test_network.py	/^        init_op = tf.global_variables_initializer()$/;"	v
instance_norm	ops.py	/^def instance_norm(x, epsilon=1e-8):$/;"	f
k	ops.py	/^def k(x):$/;"	f
keras	AngleGAN/discriminator.py	/^import keras.backend as K$/;"	i
keras	AngleGAN/generator.py	/^import keras.backend as K$/;"	i
lambda	loss.py	/^from networks.pgan.loss_utils import ecal_sum, ecal_angle # physics functions used for training the discriminator (should be in conditional lambda layer)$/;"	i
latent_dim	pgan/discriminator.py	/^    latent_dim = 1024$/;"	v
latent_dim	pgan/generator.py	/^    latent_dim = 1024$/;"	v
latent_dim	test_network.py	/^    latent_dim = 512$/;"	v
layer	loss.py	/^from networks.pgan.loss_utils import ecal_sum, ecal_angle # physics functions used for training the discriminator (should be in conditional lambda layer)$/;"	i
leaky_relu	ops.py	/^def leaky_relu(x, alpha_lr=0.2):$/;"	f
loss	loss.py	/^from networks.pgan.loss_utils import bce, mae, mape  # loss functions used for loss_fn='anglegan'$/;"	i
loss	pgan/discriminator.py	/^        loss = tf.reduce_sum(y)$/;"	v
loss	pgan/generator.py	/^        loss = tf.reduce_sum(y)$/;"	v
loss_fn	loss.py	/^from networks.pgan.loss_utils import bce, mae, mape  # loss functions used for loss_fn='anglegan'$/;"	i
mae	loss.py	/^from networks.pgan.loss_utils import bce, mae, mape  # loss functions used for loss_fn='anglegan'$/;"	i
mae	pgan/loss_utils.py	/^def mae(output, target):$/;"	f
main	test_network.py	/^def main(architecture, final_shape, real_image_input, latent_dim, base_dim, phase, loss_fn='logistic'):$/;"	f
mape	loss.py	/^from networks.pgan.loss_utils import bce, mae, mape  # loss functions used for loss_fn='anglegan'$/;"	i
mape	pgan/loss_utils.py	/^def mape(output, target):$/;"	f
math	AngleGAN/discriminator.py	/^import math$/;"	i
math	AngleGAN/generator.py	/^import math$/;"	i
math	pgan/loss_utils.py	/^import math$/;"	i
merge	AngleGAN/discriminator.py	/^from keras.layers import (Input, Dense, Reshape, Flatten, Lambda, merge,$/;"	i
merge	AngleGAN/generator.py	/^from keras.layers import (Input, Dense, Reshape, Flatten, Lambda, merge,$/;"	i
minibatch_stddev_layer	ops.py	/^def minibatch_stddev_layer(x, group_size=4):$/;"	f
np	AngleGAN/discriminator.py	/^import numpy as np$/;"	i
np	AngleGAN/generator.py	/^import numpy as np$/;"	i
np	loss.py	/^import numpy as np$/;"	i
np	ops.py	/^import numpy as np$/;"	i
np	pgan/loss_utils.py	/^import numpy as np$/;"	i
np	test_network.py	/^import numpy as np$/;"	i
num_filters	ops.py	/^def num_filters(phase, num_phases, base_shape, base_dim=None, size=None):$/;"	f
num_phases	pgan/discriminator.py	/^    num_phases = 8$/;"	v
num_phases	pgan/generator.py	/^    num_phases = 8$/;"	v
num_phases	test_network.py	/^    num_phases = 8$/;"	v
nvgpu	test_network.py	/^import nvgpu$/;"	i
optim	pgan/discriminator.py	/^        optim = tf.train.GradientDescentOptimizer(1e-5)$/;"	v
optim	pgan/generator.py	/^        optim = tf.train.GradientDescentOptimizer(1e-5)$/;"	v
os	test_network.py	/^import os$/;"	i
param	pgan/generator.py	/^                      param=0.3)$/;"	v
physics	loss.py	/^from networks.pgan.loss_utils import ecal_sum, ecal_angle # physics functions used for training the discriminator (should be in conditional lambda layer)$/;"	i
pid	test_network.py	/^                 pid = os.getpid()$/;"	v
pixel_norm	ops.py	/^def pixel_norm(x, epsilon=1e-8):$/;"	f
prep_image	pgan/loss_utils.py	/^def prep_image(images, power=1.0):$/;"	f
psutil	test_network.py	/^import psutil$/;"	i
py	test_network.py	/^                 py = psutil.Process(pid)$/;"	v
py_func	AngleGAN/discriminator.py	/^from tensorflow import py_func, float32, Tensor$/;"	i
py_func	AngleGAN/generator.py	/^from tensorflow import py_func, float32, Tensor$/;"	i
real_image_input	test_network.py	/^        real_image_input = tf.random.normal(shape=shape)$/;"	v
shape	pgan/discriminator.py	/^        shape = [1, 1] + list(np.array(base_shape)[1:] * 2 ** (phase - 1))$/;"	v
shape	pgan/generator.py	/^        shape = [1, latent_dim]$/;"	v
shape	test_network.py	/^        shape = [1, 1] + list(np.array(base_shape)[1:] * 2 ** (phase - 1))$/;"	v
should	loss.py	/^from networks.pgan.loss_utils import ecal_sum, ecal_angle # physics functions used for training the discriminator (should be in conditional lambda layer)$/;"	i
spectral_norm	ops.py	/^def spectral_norm(w, iteration=1):$/;"	f
start	test_network.py	/^            start = time.time()$/;"	v
style_mod	ops.py	/^def style_mod(x, dlatent, activation, param=None):$/;"	f
subprocess	test_network.py	/^import subprocess$/;"	i
sys	AngleGAN/discriminator.py	/^import sys$/;"	i
sys	AngleGAN/generator.py	/^import sys$/;"	i
tf	AngleGAN/discriminator.py	/^import tensorflow as tf$/;"	i
tf	AngleGAN/generator.py	/^import tensorflow as tf$/;"	i
tf	loss.py	/^import tensorflow as tf$/;"	i
tf	ops.py	/^import tensorflow as tf$/;"	i
tf	pgan/discriminator.py	/^import tensorflow as tf $/;"	i
tf	pgan/loss_utils.py	/^import tensorflow as tf$/;"	i
tf	test_network.py	/^import tensorflow as tf$/;"	i
the	loss.py	/^from networks.pgan.loss_utils import ecal_sum, ecal_angle # physics functions used for training the discriminator (should be in conditional lambda layer)$/;"	i
time	pgan/generator.py	/^import time$/;"	i
time	test_network.py	/^import time$/;"	i
to_rgb	ops.py	/^def to_rgb(x, channels=1):$/;"	f
train	pgan/discriminator.py	/^        train = optim.minimize(loss)$/;"	v
train	pgan/generator.py	/^        train = optim.minimize(loss)$/;"	v
training	loss.py	/^from networks.pgan.loss_utils import ecal_sum, ecal_angle # physics functions used for training the discriminator (should be in conditional lambda layer)$/;"	i
upscale3d	ops.py	/^def upscale3d(x, factor=2):$/;"	f
used	loss.py	/^from networks.pgan.loss_utils import bce, mae, mape  # loss functions used for loss_fn='anglegan'$/;"	i
used	loss.py	/^from networks.pgan.loss_utils import ecal_sum, ecal_angle # physics functions used for training the discriminator (should be in conditional lambda layer)$/;"	i
x	pgan/discriminator.py	/^        x = tf.random.normal(shape=shape)$/;"	v
x	pgan/generator.py	/^        x = tf.random.normal(shape=shape)$/;"	v
y	pgan/discriminator.py	/^        y = discriminator(x, 0.5, phase, num_phases, base_dim, latent_dim, activation='leaky_relu', param=0.3)$/;"	v
y	pgan/generator.py	/^        y = generator(x, 0.5, phase, num_phases, base_dim, base_shape, activation='leaky_relu',$/;"	v
